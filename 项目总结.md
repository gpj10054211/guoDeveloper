粗排模型：
上线LTR粗排
当前问题：
base学习ctr/cvr：
1.多目标排序无法感知ocpc出价，累积误差大；
2.精准值预估模型学习难度更大，同时由于模型结构和特征简单，粗排预估能力较弱；
3.曝光点击训练样本集合上，粗排相比精排ssb问题更加严重；

升级点：
1.重新定位粗排：性能约束下，选择精排认可的头部优质候选，学习目标尽可能和精排一致；
2.前置实验：给精排扩候选观察线上存在效果空间，说明粗排能力需要进一步提升；
3.学习目标：学习ctr/cvr（精准值预估）->直接学习精排排序结果（集合选择），保持链路一致性，模型学习更简单。端到端建模，减少累积误差。
4.训练样本：曝光点击集合->精排候选集合，样本数量扩充上百倍，有效缓解ssb问题；
5.离线评测指标：曝光点击auc->一致性auc、hitrate、ndcg，表征和精排的一致性；

持续优化LTR粗排
特征挖掘：引入周期、转化、曝光行为序列
训练样本：
1.位次感知：初版LTR基于精排topk作为正样本label，非topk作为负样本label，进行pointwise建模，所有正样本label均为1，没有进行排序位次加权。由于不同位次的候选质量不同，因此针对不同排序位次的候选进行动态加权训练，使得模型训练时对不同排序位次的样本有所区分。
2.样本不均衡：训练样本由曝光点击升级为精排候选后，正负样本均有成倍的增加，正负样本比例由1：20变成1：80，正样本+5倍（点击1->曝光5）,负样本+20倍（曝光20->精排候选400），样本不均衡进一步加剧。基于此进行负样本降采样和模型loss升级（logloss->加权focloss）。
3.分档pair建模：升级成pairwise建模，构造正负pair时进行分档处理，细粒度样本序学习。具体来说：
1）将精排候选按照精排序分割为若干个档位，每个档位包含一组位置相邻的广告，构造训练数据时仅对散落在不同档位的广告组pair，同一档位内的广告不组pair；
2）增加头部pair和长间距pair的权重，降低尾部pair的权重，重点关注头部子集合序的正确性，排名靠后的广告不会被精排选中曝；
4.对比学习：针对长尾流量如何增加曝光问题，尝试引入对比学习丰富训练样本。
借鉴"对比学习"的思想，在粗排模型中引入CL辅助任务，通过学习item2item和user2user之间的模态关系，解决"少数人群+冷门物料，标注样本少"的问题，让item tower对冷门、小众item也能够学习出高质量的embedding，从而提升长尾流量曝光。

建模方式：
1.时空场景化建模：在点击序列的不同行为之间，考虑场景的时间/空间差异，对用户短期场景、近距离场景兴趣进行了挖掘。参考BERT等模型中广泛使用的position embedding，引入时间和距离信息，在pooling聚合时区分不同实时和不同距离行为的贡献度。具体来说：
1）时间attention：针对当前请求，增加当前请求与行为序列的时间差作为权重，区分不同实时性的行为对当前用户意图表征的贡献度，再对序列中所有行为表征加权求和；
2）距离attention：针对当前请求，增加当前请求与行为序列的距离作为权重，区分不同远近的行为对当前用户意图表征的贡献度，再对序列中所有行为表征加权求和；

2.多场景融合建模：推荐广告位众多，逐位置建模优化、维护成本较高，且各位置用户行为和广告数据存在一定的共性和特异性，因而考虑将多广告位场景数据融合建模，但模型如何学到不同广告位的共性，同时有效区分单个广告位的特性，存在一定挑战。
选型时参考Star模型的建模思路，构造Star Topology中shared fcn和specific fcn，shared fcn学习全场景样本，拟合所有广告位的共性，specific fcn学习私有域样本，拟合不同广告位的差异性。
1）传统多任务模型如MMOE、PLE主要应用于相同场景下的不同任务，如同时预估单样本的CTR、CVR；
2）多场景融合建模主要应用于不同场景的相同任务建模，Star Topology拟合不同场景的共性和差异性，更符合我们的任务特点。

3.bid敏感建模：基于出价动态调整粗排序，同时保证出价和粗排序的一致性。
1）bid是广告主的重要抓手，广告主通过调价参与到广告系统的博弈中，保证广告主出价对排序的单调撬动能力至关重要。
2）当前的pairwise loss建模无法保证bid对排序的单调撬动能力。
3）建模方式上升级pairwise loss，原始loss是通过比较模型预估分大小计算loss，改进后是在原始模型预估分s的基础上 * 原始出价bid，通过比较pair对之间的s*bid相对差值计算loss，线上基于s*bid进行排序。

DNN结构升级
DNN升级是一项系统性复杂工程，由于模型复杂度的大幅度增加，耗时和机器资源都会有大幅度的增加，因此升级的关键通过算力和模型复杂度简化来满足链路性能，同时能够提升线上效果。我们以精排模型作为最复杂的初版DNN模型，上线初期无法满足性能和机器资源要求。
我们将粗排耗时分为特征相关和模型相关两部分，特征相关的耗时占比为2/3，模型相关的耗时占比1/3。从特征和模型两部分去进行优化，主要包括特征选择、计算精度简化、网络搜索、模型蒸馏、时延建模、精排候选调整。
1、特征选择：是特征工程里的一个重要问题，其目标是寻找最优的特征子集，删除不相关的冗余特征，从而达到减少特征个数，降低运行时间的目的。这里的关键是如何建模特征重要度，基于特征重要度进行特征选择。调研业界，我们尝试了两种特征重要度建模方法：
1）引入特征掩码参数学习特征重要度：给每个特征的embedding结果加一个扰动变量，使其以一定的概率出现在神经网络中，同时加入正则，使得低重要度的特征出现在神经网络中的概率低，该方法假设每个特征的重要度服从先验分布，和真实数据分布有一定的偏差；
2）基于se-net block自动提取每个特征的重要度，动态的做特征通道交互，本质是attention操作。每个特征以一个Bit来表征，通过MLP来进行交互，对于当前所有输入的特征，通过相互发生关联，来动态地判断哪些特征重要，哪些特征不重要。具体包括squeeze阶段和excitation阶段，
sequeeze阶段：对每个特征的embedding做信息汇总和压缩，每个特征embedding得到一个值；
excitation阶段：引用两层mlp，第一层mlp做特征的相互交互，动态判断哪些特征重要，哪些特征不重要，第二层mlp是为了保证输出的维度和输入特征个数一致，以此得出每个特征的重要度；
attentive embedding layer：特征重要度和特征embedding进行加权；
离线选择时：基于每个特征在所有样本的重要度平均值作为该特征的重要度打分，从高往低进行排序，选择不同topk特征集合子集平衡效率和效果。

2、计算精度简化：
1）混合精度: 部分可能超出Float16的层使用32位精度（sumpooling，BN），其他层Float32位简化为Float16，一定程度上提升模型性能。
2）模型量化: 通常模型的权重存储为32位浮点数，这远比所需的精度高，可以通过量化这些权重来节省空间和时间，同时对精度产生最小的影响。通过减少表示每个权重参数所需的比特数来压缩原始网络，从而实现计算加速。

3、网络搜素：基于神经网络结构搜索方法(NAS)，给定网络结构候选下，自动学习网络结构的重要度，进行网络结构选择，依赖预先设定的一组模型结构。主要工作包括三个部分，分别是网络结构搜索空间、搜索策略、性能评估。
搜索空间：固定网络层数为3层mlp，每一层mlp为包含不同节点个数的操作算子，包括32，64，128，256，512 5个包含不同节点的操作算子，每一层只选择1个操作算子，整体网络结构可搜索的个数为5*5*5=125；
搜索策略：每一层搜索网络的每个操作算子i，引入对应的一个实值参数pi,包括p1,p2,p3,p4,p5，通过softmax函数后表征每个操作算子的重要度。
1）第一层：输入为特征embedding  concate聚合层（512），通过全连接的形式聚合每个操作算子，加权对应的pi，得到第一层的各个操作算子输出（32，64，128，256，512）；
2）第二层：以第一层的各个操作算子的输出进行聚合，同样的方式作用到第二层的各个操作算子，加权对应的pi，得到第二层的各个操作算子输出（32，64，128，256，512）；
3）第三层：以第二层的各个操作算子的输出进行聚合，同样的方式作用到第三层的各个操作算子，加权对应的pi，得到第三层的各个操作算子输出（32，64，128，256，512）；
最后第三层的操作算子聚合得到预估值，进行loss训练。
性能评估：基于每一层的操作算子重要度pi,选择top1作为每一层的算子。

4、模型蒸馏：为了降低耗时和机器资源，我们基于特征重要度和网络搜素方法对特征和模型结构进行了大幅度的精简，会降低模型的精准度。为了提升模型的能力，通过大模型蒸馏的方式提升DNN粗排的容量，上线了中间表征层蒸馏和logit蒸馏两种。
5、精排候选调整：
粗排模块升级后，预期会带来线上耗时的增加。但是粗排能力的提升预期可以减少下游排序压力，改善排序模块的耗时，从而使得链路总耗时满足约束。为了尽可能减小粗排截断后对效果的影响，我们离线模拟不同的粗排截断下，粗排hitrate指标的变化情况，对精排的候选进行调整。


链路漏斗
LBS场景下候选量相对有限，在性能和算力约束下，通过扩充类型供给、升级全城召回策略、动态算力等，从源头处打开链路空间，突破单模块优化边际效应递减的限制。
1、供给上新增多种实体类型，设计离线优选和在线探索利用实验机制，保证新类型供给质量；
背景：历史广告侧候选供给类型相对单一，只有门店这一种供给类型。而平台侧的自然内容供给形式较为丰富，包含团购、泛商品、笔记、视频等商品类型，因此考虑引入平台侧的多种形式供给。在提升业务效果的同时，大幅度增加广告候选，为全链路打开优化空间。
问题：新增类型供给的质量差别较大，同时链路各模块的打分存在偏差，直接全部引入业务效果短期内无法打平，因此需要从离线优选和在线实验机制进行调整优化。
动作：
1）离线设计优选策略，包括几个部分：基于自然内容的ctcvr进行优选截断，基于团单、泛商品的销量、折扣进行优选，基于对应的图片质量分进行优选；
2）为了在保证实验效果的同时，尽可能提升新增类型的曝光占比，设计在线探索利用实验机制。实验流量包括20%的探索和80%的利用，探索流量仅仅出新增的优选类型供给，同时进行扶持；利用流量上的供给，会基于后验曝光转化效果进行优选得到，尽可能保证线上效果。
结果：候选供给平均增加5倍，大幅度提升了链路优化空间；线上效果收入+3%；

2、召回策略上升级全城召回，突破多路兴趣的限制，扩大召回出口；
背景：供给候选大幅度增加后，受限于多路兴趣召回相对严格的限制，无法有效增加下游粗排和精排的候选，从而没有真正打开链路的候选空间。
动作：尝试在性能允许的情况下探索全召回，以充分扩充召回候选，发挥下游粗排和精排的作用。我们对中小城市进行了全召回，大城市结合隐式的模型召回扩量。
结果：平均粗排和精排候选整体增加近2倍，其中小城市召回增加5倍，线上效果收入+10%。

3、模型上进行预估粒度升级、调整采样方法，应对新候选打分偏差的问题；。
背景：供给类型的大幅度增加和召回候选的大幅度增加会带来粗排和精排候选分布的剧烈变化。当前下游模型建模粒度仍然为原始的门店粒度，在预估时无法感知同商户下不同类型实体的区别，缺乏对用户兴趣在多实体维度的个性化刻画，各模块对新候选类型的打分存在明显的偏低。
动作：模型预估粒度由门店poi粒度升级到实体粒度（粗->细），负采样由商户粒度到多实体粒度。
结果：线上效果收入+5%。

4、设计类目和商户保送机制，结合粗排多目标调整，应对流量分配、用户/商户体验等风险；
问题：在Base框架中，链路各个环节在原始ECPM最大化下形成了一定的平衡。全城召回由于去除了多路兴趣限制，会带来候选分布的极大变化，受链路机制偏向于高出价影响，在带来线上收入大幅度提升的同时，会导致：
1）整体和分类目，用户体验和商户体验均明显负向；
2）导致曝光商户更加集中；
动作：
1）针对整体和分类目ctcvr明显负向的问题，结合粗排模型进行样本和多目标的调整，对高出价类目的正样本进行降采样和目标loss的降权；
2）针对类目集中的问题，设计二级类目保送机制，每个二级类目下至少保证一个候选给到下游；
3）针对曝光商户集中的问题，设计商户保送机制，商户poi广告不进行粗排截断，直接送给下游，其他多种类型实体进行粗排分排序截断；针对新商户，会以1%的概率随机保送到精排；
结果：整体ctcvr+2%，给精排的一级类目多样性+59%，曝光商户数持平；

5、性能和资源上通过模型/策略的融合和简化、动态算力等进行优化。

模型/策略的融合和简化：
问题：随着优化的持续进行，链路面临一些挑战和问题：多路召回性能堪忧，通道覆盖流量比例不大，优化效率偏低，通道之间重复度高，缺乏协同性。针对上述问题，我们对召回通道进行融合和简化。
动作：1. 砍掉小众琐碎的召回通道，占比少的直接删减，占比多的将相应信息和能力融入到召回模型中去，从而完成精简；2. 召回模型进行多场景的融合。

动态算力：系统算力约束下，针对不同价值流量进行差异化的算力分配，实现系统收益的最大化。
在精排模块以弹性队列的方式进行落地，针对不同价值的流量，选择不同的动作档位，对精排的候选进行动态调整。

流量价值预估：在召回模块引入价值预估模型，和多路召回并行，基本不增加链路性能和机器资源。输入：用户profile、行为序列、上下文场景等特征，label: 单次请求的系统收入，预估值：单次pv请求获得的ecpm。
为了获得当前流量在不同动作档位下的系统收益，需要考虑各档位对原始预估ecpm的折损情况。
这里我们可选的动作档位是不同长度的候选队列，包括top200、top400一直到top2000，我们根据不同档位候选的粗排总分除以所有候选的粗排总分作为所选择档位的权重v，乘以对应的原始预估ecpm即可得到该档位下的系统收益。

流量成本预估：这里我们是以候选的队列长度进行评估的，在流量和模型不变的情况下，系统算力消耗和候选队列长度正相关。不同档位的候选长度就代表所消耗的算力。
动态算力分配：针对当前请求，基于上述预估得到的不同档位下的流量价值Q和算力消耗k，进行最优动作的决策。具体来说：选择Q-lambda * k值最大的档位作为本次的候选队列，动态调整精排候选。这里lambda 是基于离线二分迭代求解得到的。
动态算力求解：假设系统的算力容量为C，则约束条件为：lambda * k <= C, 优化目标为最大化不同动作的收益，max sum(Q), 求解变量为lmbda。基于过去15分钟收集到log日志，进行二分求解lmbda值，然后更新线上做最优决策。

召回模块：
1、向量化召回模型：兴趣召回模型的负样本迭代，上线LTR召回。
兴趣召回模型：引入曝光/精排日志丰富正负样本，规则式、多轮迭代式和对抗式负样本挖掘；
背景：线上为base双塔，正样本为点击数据，负采样为全称随机负采样，每个样本随机配6个负样本，loss为hignloss
动作：
1）正样本增强：
a) 引入高ctr的曝光样本补充正样本：借鉴word2vector中的高频样本采样思路，后验统计广告的ctr，对于ctr高于一定阈值的曝光样本，以概率P进行采样引入，ctr越高，作为正样本的概率越高；
b) 引入精排tok样本作为补充正样本：以概率P进行采样引入，广告的预估ecpm越高，作为正样本的概率越高；
2）负样本采样：
a）引入低ctr的曝光样本作为负样本：对于ctr低于一定阈值的曝光样本以概率P进行负采样，ctr越低，采样概率越高
b) 规则式：采样正样本同级类目/一定距离内/同pv的非topk精排候选的广告作为hard负样本，提高模型学习细粒度信息的能力
c) 多轮迭代式：渐进式负采样的方案，主要的思想是多轮训练机制，首先利用"easy"样本生成初版模型，期望模型能够学习到较粗粒度的信息，后续多轮训练中，逐步加入"hard"样本，让模型能够学习不同粒度的信息。
第一轮训练随机负采样生成“easy”样本，产出初版模型M1，后续多轮训练中基于上一轮模型产出的向量将候选广告聚类，向量能够综合各个特征的信息，所以能够兼顾各个维度的相关性。同个类别中的节点互为"hard"样本，在后续负采样中，只采样同类别的样本作为负样本。
d）对抗式：参考facebook和莫比乌斯的采样思路，以精排预估靠后且base模型打分靠前的候选广告作为hard负样本，通过召回和精排打分不一致的角度引入hard负样本；
e) 模型loss升级为batch hard：对于每一个anchor，6个负样本中选择最hard的负样本(距离anchor最小的negative example)参与训练，加大模型学习的难度。
2、i2i召回：新增语义、共现、类目等多路显示通路；
1）语义召回：基于用户历史搜索query信息, 训练query-item的双塔召回模型，离线缓存每个query下对应的广告候选，供线上召回使用；
2）共现召回：针对详情页场景，基于同点击session的自然和广告数据，session每个广告/自然商户作为key，同session其他广告为value，供线上召回使用；
3）类目召回：基于用户历史点击的广告，拿到对应的二级类目列表，建立以偏好类目为key，类目下所有候选为value的倒排索引，供线上召回使用；
